# ExtraAWQ
ExtraAWQ : Improved AWQ(Activation-aware Weight Quantization) with extra scaling (2024 Fall graduation project)

2024/12/19 : The code is uploaded.

Since the original files were lost, the updated part in the code might have some errors.

This work is based on [AWQ](https://github.com/mit-han-lab/llm-awq). /awq/quantize/autoscale.py is the only revised file. The inserted code is in search_module_scale() under auto_scale_block().
![alt text](https://github.com/jundaree/ExtraAWQ/blob/main/poster.jpg?raw=true)

